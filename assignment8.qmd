---
title: "assignment 8"
output:
    html_document:
        toc: true
        toc_float: true
---

```{r}

require(ISLR)
require(MASS)
require(descr)
attach(Smarket)

## Linear Discriminant Analysis
freq(Direction)
train = Year<2005
lda.fit=lda(Direction~Lag1+Lag2,data=Smarket, subset=Year<2005)
lda.fit
plot(lda.fit, col="lightgreen")
Smarket.2005=subset(Smarket,Year==2005) # Creating subset with 2005 data for prediction
lda.pred=predict(lda.fit,Smarket.2005)
names(lda.pred)
lda.class=lda.pred$class
Direction.2005=Smarket$Direction[!train] 
table(lda.class,Direction.2005) 
data.frame(lda.pred)[1:5,]
table(lda.pred$class,Smarket.2005$Direction)
mean(lda.pred$class==Smarket.2005$Direction)



```

# ANSWER 1:

While the best subset selection model may have the smallest training RSS, stepwise selection models, particularly those using test RSS as a criterion, aim to find models that generalize well to unseen data. The choice between forward and backward models depends on the dataset and should be evaluated using appropriate validation techniques.

**Best Subset Selection Model:**

Best subset selection involves fitting all possible combinations of predictors and selecting the model with the lowest training RSS. Since it considers all possible subsets of predictors, it tends to find the model that fits the training data best among all the candidates. However, selecting the best subset based solely on training RSS can lead to overfitting, especially with a large number of predictors, as the model may capture noise in the data.

**Stepwise Selection Models:**

Stepwise selection methods, such as forward and backward selection, involve adding or removing predictors iteratively based on certain criteria (e.g., AIC, BIC, adjusted R-squared) until a stopping criterion is met.

While stepwise selection methods aim to find a parsimonious model that generalizes well to unseen data, they typically use techniques like cross-validation to estimate the performance of the selected model on test data.
Therefore, the model selected through stepwise selection often has the smallest test RSS, indicating better generalization performance compared to the best subset selection model.

**Forward vs. Backward Models:**

In forward selection, predictors are added one by one to the model until no significant improvement in the chosen criterion is observed. This approach may result in a model that is simpler and potentially more interpretable.

In backward elimination, all predictors are initially included in the model, and one by one, the least significant predictors are removed until no further improvement is observed. This method may lead to a more parsimonious model, especially when dealing with a large number of predictors.

The choice between forward and backward selection may vary depending on the dataset characteristics, such as the correlation between predictors and the signal-to-noise ratio. It's essential to assess the performance of both methods through cross-validation or other validation techniques to determine which one yields the best test RSS for the specific dataset.


```{R}
set.seed(123)
x <- rnorm(100)
eps <- rnorm(100)

y <- 4 + 9 * x + 2 * x^2 + x^3 + eps

plot(x)
plot(y)

require(leaps)

best_subset <- regsubsets(y ~ poly(x, 10, raw = T), data = data.frame(y,x, nvmax = 10))
bic <- summary(best_subset)$bic
cp <- summary(best_subset)$cp
adjr2 <- summary(best_subset)$adjr2

plot(bic, type = "b", pch = 16, col = "cyan", 
     xlab = "Model Number", ylab = "BIC Value", 
     main = "BIC Values for Different Models")
plot(cp, type = "b", pch = 16, col = "cyan", 
     xlab = "Model Number", ylab = "Cp Value", 
     main = "Cp Values for Different Models")
plot(adjr2, type = "b", pch = 16, col = "cyan", 
     xlab = "Model Number", ylab = "Adjusted R^2 Value", 
     main = "Adjusted R^2 Values for Different Models")

which.min(bic)
which.min(cp)
which.max(adjr2)

coef(best_subset, id = 3)
```

# Answer 2:

Model 3 is the best as it has the lowest BIC and Cp values. However, Model 7, with the highest adjusted R squared value, might be overfitting as the R squared plot levels off at Model 3. In Model 3, the coefficients are: intercept (3.97), B1 (8.92), B2 (1.91), and B3 (1.02).

```{R}
for_subset <- regsubsets(y ~ poly(x, 10, raw = T), data = data.frame(y,x, nvmax = 10), method = "forward")

plot(summary(for_subset)$bic, type = "b", pch = 16, col = "orange", 
     xlab = "Model Number", ylab = "BIC Value", 
     main = "BIC Values for Different Models")
plot(summary(for_subset)$cp, type = "b", pch = 16, col = "pink", 
     xlab = "Model Number", ylab = "Cp Value", 
     main = "Cp Values for Different Models")
plot(summary(for_subset)$adjr2, type = "b", pch = 16, col = "steelblue", 
     xlab = "Model Number", ylab = "Adjusted R^2 Value", 
     main = "Adjusted R^2 Values for Different Models")

which.min(summary(for_subset)$bic)
which.min(summary(for_subset)$cp)
which.max(summary(for_subset)$adjr2)


coef(for_subset, id = 3)
```

**Answer 3**

Model 3 is the best again, having the lowest BIC and Cp values. While Model 4 has the highest adjusted R squared value, Model 3 shows a similar value in the plot. In Model 3, the coefficients are: intercept (3.97), B1 (8.92), B2 (1.91), and B3 (1.02).

```{R}
bac_subset <- regsubsets(y ~ poly(x, 10, raw = T), data = data.frame(y,x, nvmax = 10), method = "backward")

plot(summary(bac_subset)$bic, type = "b", pch = 16, col = "cyan", 
     xlab = "Model Number", ylab = "BIC Value", 
     main = "BIC Values for Different Models")
plot(summary(bac_subset)$cp, type = "b", pch = 16, col = "lightgreen", 
     xlab = "Model Number", ylab = "Cp Value", 
     main = "Cp Values for Different Models")
plot(summary(bac_subset)$adjr2, type = "b", pch = 16, col = "magenta", 
     xlab = "Model Number", ylab = "Adjusted R^2 Value", 
     main = "Adjusted R^2 Values for Different Models")

which.min(summary(bac_subset)$bic)
which.min(summary(bac_subset)$cp)
which.max(summary(bac_subset)$adjr2)

coef(bac_subset, id = 3)
```


# Answer 3:

Model 4, using backwards stepwise selection, outperforms others across all three metrics. The coefficients are as follows: intercept (3.96), B1 (9.89), B2 (1.97), and B3 (0.17).
